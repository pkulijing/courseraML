\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Univariate linear regression}{1}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Hypothesis function and cost function}{1}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Gradient descent}{1}{subsection.2.2}}
\newlabel{gddef}{{3}{2}{Gradient descent}{equation.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Multivariate linear regression}{2}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Hypothesis function and cost function}{2}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Feature scaling}{3}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Learning rate $\alpha $}{3}{subsection.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Analytical solution: normal equation}{3}{subsection.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Logistic regression}{4}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Hypothesis function and cost function}{4}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}One-vs-all classification}{4}{subsection.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Regularization: solution to overfitting}{5}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Cost function of regularization}{5}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Regularized linear regression}{5}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Regularized logistic regression}{6}{subsection.5.3}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Neural network}{6}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Introduction}{6}{subsection.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Basic logistic unit in a neural network\relax }}{7}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{neuralunit}{{1}{7}{Basic logistic unit in a neural network\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A simple neural network\relax }}{7}{figure.caption.3}}
\newlabel{neuralnetwork}{{2}{7}{A simple neural network\relax }{figure.caption.3}{}}
\newlabel{neuralnetworkeqs}{{21}{8}{Introduction}{equation.6.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Examples}{8}{subsection.6.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Implementation of logical AND/OR with neural network\relax }}{8}{figure.caption.4}}
\newlabel{neuraland}{{3}{8}{Implementation of logical AND/OR with neural network\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Implementation of logical NOT with neural network\relax }}{8}{figure.caption.5}}
\newlabel{neuralnot}{{4}{8}{Implementation of logical NOT with neural network\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Implementation of logical XNOR with neural network\relax }}{9}{figure.caption.6}}
\newlabel{neuralxnor}{{5}{9}{Implementation of logical XNOR with neural network\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Cost function}{9}{subsection.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Backpropagation}{9}{subsection.6.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Summary}{11}{subsection.6.5}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Machine learning diagnostics}{11}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Evaluate a hypothesis: test set}{12}{subsection.7.1}}
\newlabel{jtestlor}{{30}{12}{Evaluate a hypothesis: test set}{equation.7.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Model selection: cross-validation set}{12}{subsection.7.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Bias \& variance}{13}{subsection.7.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Diagnosing bias and variance with errors: different polynomial degrees\relax }}{13}{figure.caption.7}}
\newlabel{biasvariance}{{6}{13}{Diagnosing bias and variance with errors: different polynomial degrees\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Diagnosing bias and variance with errors: different regularization parameter\relax }}{14}{figure.caption.8}}
\newlabel{lambdachoice}{{7}{14}{Diagnosing bias and variance with errors: different regularization parameter\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Learning curve}{14}{subsection.7.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces A typical learning curve\relax }}{15}{figure.caption.9}}
\newlabel{learningcurve}{{8}{15}{A typical learning curve\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Learning curve with high bias\relax }}{15}{figure.caption.10}}
\newlabel{highbiascurve}{{9}{15}{Learning curve with high bias\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Learning curve with high variance\relax }}{16}{figure.caption.11}}
\newlabel{highvariancecurve}{{10}{16}{Learning curve with high variance\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}Conclusion}{16}{subsection.7.5}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Machine learning system design}{16}{section.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Error analysis}{17}{subsection.8.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Handling skewed data}{17}{subsection.8.2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Definitions for skewed data error metrics\relax }}{17}{table.caption.12}}
\newlabel{skeweddefs}{{1}{17}{Definitions for skewed data error metrics\relax }{table.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Data}{18}{subsection.8.3}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Support vector machine (SVM)}{18}{section.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Cost function}{18}{subsection.9.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Image of cost1(z)\relax }}{19}{figure.caption.13}}
\newlabel{cost1}{{11}{19}{Image of cost1(z)\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Image of cost0(z)\relax }}{19}{figure.caption.14}}
\newlabel{cost0}{{12}{19}{Image of cost0(z)\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Large margin classification}{20}{subsection.9.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Intuition of large margin classification\relax }}{20}{figure.caption.15}}
\newlabel{largemargin}{{13}{20}{Intuition of large margin classification\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Mathematical background of large margin classification\relax }}{20}{figure.caption.16}}
\newlabel{largemarginmath}{{14}{20}{Mathematical background of large margin classification\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3}Kernals}{21}{subsection.9.3}}
\newlabel{polyfeatures}{{37}{21}{Kernals}{equation.9.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4}Logistic regression v.s. SVM}{22}{subsection.9.4}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Clustering}{22}{section.10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}K-means algorithm}{22}{subsection.10.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}Optimization objective}{23}{subsection.10.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3}Random initialisation}{23}{subsection.10.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.4}Choice of K}{23}{subsection.10.4}}
\@writefile{toc}{\contentsline {section}{\numberline {11}Dimensionality reduction}{24}{section.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1}Formulation of PCA}{24}{subsection.11.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2}Implementation of PCA}{25}{subsection.11.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3}Mathematics of SVD}{25}{subsection.11.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.4}Choice of k}{25}{subsection.11.4}}
\newlabel{choiceofk}{{43}{25}{Choice of k}{equation.11.43}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.5}Good use v.s. bad use}{25}{subsection.11.5}}
\@writefile{toc}{\contentsline {section}{\numberline {12}Anomaly detection}{26}{section.12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1}Introduction}{26}{subsection.12.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2}Algorithm}{26}{subsection.12.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3}Developing and evaluating an anomaly detection system}{27}{subsection.12.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.4}Anomaly detection v.s. supervised learning}{27}{subsection.12.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.5}Choosing features to use}{28}{subsection.12.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.6}Multivariate Gaussian distribution}{28}{subsection.12.6}}
\@writefile{toc}{\contentsline {section}{\numberline {13}Recommender systems}{29}{section.13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1}Introduction}{29}{subsection.13.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2}Collaborative filtering algorithm}{30}{subsection.13.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3}Mean normalization}{31}{subsection.13.3}}
\@writefile{toc}{\contentsline {section}{\numberline {14}Large scale machine learning}{31}{section.14}}
\@writefile{toc}{\contentsline {section}{\numberline {15}Example: photo OCR}{31}{section.15}}
