\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{Univariate linear regression}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{Hypothesis function and cost function}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{Gradient descent}{section.2}% 4
\BOOKMARK [1][-]{section.3}{Multivariate linear regression}{}% 5
\BOOKMARK [2][-]{subsection.3.1}{Hypothesis function and cost function}{section.3}% 6
\BOOKMARK [2][-]{subsection.3.2}{Feature scaling}{section.3}% 7
\BOOKMARK [2][-]{subsection.3.3}{Learning rate }{section.3}% 8
\BOOKMARK [2][-]{subsection.3.4}{Analytical solution: normal equation}{section.3}% 9
\BOOKMARK [1][-]{section.4}{Logistic regression}{}% 10
\BOOKMARK [2][-]{subsection.4.1}{Hypothesis function and cost function}{section.4}% 11
\BOOKMARK [2][-]{subsection.4.2}{One-vs-all classification}{section.4}% 12
\BOOKMARK [1][-]{section.5}{Regularization: solution to overfitting}{}% 13
\BOOKMARK [2][-]{subsection.5.1}{Cost function of regularization}{section.5}% 14
\BOOKMARK [2][-]{subsection.5.2}{Regularized linear regression}{section.5}% 15
\BOOKMARK [2][-]{subsection.5.3}{Regularized logistic regression}{section.5}% 16
\BOOKMARK [1][-]{section.6}{Neural network}{}% 17
\BOOKMARK [2][-]{subsection.6.1}{Introduction}{section.6}% 18
\BOOKMARK [2][-]{subsection.6.2}{Examples}{section.6}% 19
\BOOKMARK [2][-]{subsection.6.3}{Cost function}{section.6}% 20
\BOOKMARK [2][-]{subsection.6.4}{Backpropagation}{section.6}% 21
\BOOKMARK [2][-]{subsection.6.5}{Summary}{section.6}% 22
\BOOKMARK [1][-]{section.7}{Machine learning diagnostics}{}% 23
\BOOKMARK [2][-]{subsection.7.1}{Evaluate a hypothesis: test set}{section.7}% 24
\BOOKMARK [2][-]{subsection.7.2}{Model selection: cross-validation set}{section.7}% 25
\BOOKMARK [2][-]{subsection.7.3}{Bias \046 variance}{section.7}% 26
\BOOKMARK [2][-]{subsection.7.4}{Learning curve}{section.7}% 27
\BOOKMARK [2][-]{subsection.7.5}{Conclusion}{section.7}% 28
\BOOKMARK [1][-]{section.8}{Machine learning system design}{}% 29
\BOOKMARK [2][-]{subsection.8.1}{Error analysis}{section.8}% 30
\BOOKMARK [2][-]{subsection.8.2}{Handling skewed data}{section.8}% 31
\BOOKMARK [2][-]{subsection.8.3}{Data}{section.8}% 32
\BOOKMARK [1][-]{section.9}{Support vector machine \(SVM\)}{}% 33
\BOOKMARK [2][-]{subsection.9.1}{Cost function}{section.9}% 34
\BOOKMARK [2][-]{subsection.9.2}{Large margin classification}{section.9}% 35
\BOOKMARK [2][-]{subsection.9.3}{Kernals}{section.9}% 36
\BOOKMARK [2][-]{subsection.9.4}{Logistic regression v.s. SVM}{section.9}% 37
\BOOKMARK [1][-]{section.10}{Clustering}{}% 38
\BOOKMARK [2][-]{subsection.10.1}{K-means algorithm}{section.10}% 39
\BOOKMARK [2][-]{subsection.10.2}{Optimization objective}{section.10}% 40
\BOOKMARK [2][-]{subsection.10.3}{Random initialisation}{section.10}% 41
\BOOKMARK [2][-]{subsection.10.4}{Choice of K}{section.10}% 42
\BOOKMARK [1][-]{section.11}{Dimensionality reduction}{}% 43
\BOOKMARK [2][-]{subsection.11.1}{Formulation of PCA}{section.11}% 44
\BOOKMARK [2][-]{subsection.11.2}{Implementation of PCA}{section.11}% 45
\BOOKMARK [2][-]{subsection.11.3}{Mathematics of SVD}{section.11}% 46
\BOOKMARK [2][-]{subsection.11.4}{Choice of k}{section.11}% 47
\BOOKMARK [2][-]{subsection.11.5}{Good use v.s. bad use}{section.11}% 48
\BOOKMARK [1][-]{section.12}{Anomaly detection}{}% 49
\BOOKMARK [2][-]{subsection.12.1}{Introduction}{section.12}% 50
\BOOKMARK [2][-]{subsection.12.2}{Algorithm}{section.12}% 51
\BOOKMARK [2][-]{subsection.12.3}{Developing and evaluating an anomaly detection system}{section.12}% 52
\BOOKMARK [2][-]{subsection.12.4}{Anomaly detection v.s. supervised learning}{section.12}% 53
\BOOKMARK [2][-]{subsection.12.5}{Choosing features to use}{section.12}% 54
\BOOKMARK [2][-]{subsection.12.6}{Multivariate Gaussian distribution}{section.12}% 55
\BOOKMARK [1][-]{section.13}{Recommender systems}{}% 56
\BOOKMARK [2][-]{subsection.13.1}{Introduction}{section.13}% 57
\BOOKMARK [2][-]{subsection.13.2}{Collaborative filtering algorithm}{section.13}% 58
\BOOKMARK [2][-]{subsection.13.3}{Mean normalization}{section.13}% 59
\BOOKMARK [1][-]{section.14}{Large scale machine learning}{}% 60
\BOOKMARK [2][-]{subsection.14.1}{Problem with large scale data}{section.14}% 61
\BOOKMARK [2][-]{subsection.14.2}{Stochastic gradient descent}{section.14}% 62
\BOOKMARK [2][-]{subsection.14.3}{Mini batch gradient descent}{section.14}% 63
\BOOKMARK [2][-]{subsection.14.4}{Convergence}{section.14}% 64
\BOOKMARK [2][-]{subsection.14.5}{Online learning}{section.14}% 65
\BOOKMARK [2][-]{subsection.14.6}{Map/reduce and parallelism}{section.14}% 66
\BOOKMARK [1][-]{section.15}{Example: photo OCR}{}% 67
